# Robustness: STDP-based Training for Adversarially Robust Spiking Neural Networks

This repository contains the code implementation of the paper:

> **ìŠ¤íŒŒì´í‚¹ ì‹ ê²½ë§ì˜ ì ëŒ€ì  ê°•ê±´ì„±ì„ ìœ„í•œ STDP ê¸°ë°˜ í•™ìŠµ**  
> ì´ì›ëª¨, ì„±ë°±ë¥œ, ê³ ìƒê¸°  
> University of Seoul, Department of AI, CIDA Lab

## ğŸ§  Overview

Spiking Neural Networks (SNNs) are attracting attention due to their energy efficiency and biological plausibility. However, their vulnerability to adversarial attacks remains a challenge.

This work explores how **STDP (Spike-Timing Dependent Plasticity)**, a biologically inspired unsupervised learning rule, can be used to improve the **adversarial robustness** of SNNs. The study compares:

- Conventional CNNs
- Surrogate gradient-based SNNs
- STDP-enhanced SNNs

against adversarial attacks such as FGSM on MNIST and CIFAR-10 datasets.

## ğŸ§ª Key Findings

| Dataset  | Model       | Test Acc (%) | Adv. Acc (%) | ASR (%)   |
|----------|-------------|--------------|--------------|-----------|
| MNIST    | CNN         | 99.24        | 41.67        | 57.57     |
| MNIST    | SNN         | 99.20        | 70.90        | 28.27     |
| MNIST    | SNN + STDP  | 99.25        | 80.57        | 18.78     |
| CIFAR-10 | CNN         | 87.09        | 50.95        | 37.31     |
| CIFAR-10 | SNN         | 75.39        | 65.05        | 11.82     |
| CIFAR-10 | SNN + STDP  | 75.05        | 64.32        | 10.71     |

- **SNN+STDP** models showed significantly lower adversarial attack success rates compared to CNNs and vanilla SNNs.
- STDP encourages sparse connectivity, which limits gradient-based attack pathways.

## âš™ï¸ Repository Structure

```bash
Robustness/
â”œâ”€â”€ images/               # Visualization results
â”œâ”€â”€ utils/                # Dataset loading, attack utils, training utilities
â”œâ”€â”€ train_cifar10.sh      # Main training script on CIFAR10 dataset
â”œâ”€â”€ train_mnist.sh        # Main training script on MNIST dataset
â”œâ”€â”€ main.py               # Main implementation
â”œâ”€â”€ visualizing.py        # Visualization of learned weight sparsity
â””â”€â”€ README.md




## How to run?

### Train CNN
```bash
python -m train --net CNN -t 10 --seed 0 --dset MNIST --attack --epsilon 0.1
```

### Train SNN
```bash
python -m train --net SNN -t 10 --seed 0 --dset MNIST --no-attack
```

### Train STDP
```bash
python -m train --net STDP -t 10 --seed 0 --dset MNIST --attack
```
